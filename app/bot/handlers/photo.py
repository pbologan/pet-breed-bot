import os
from pathlib import Path
from aiogram import Router, F
from aiogram.types import Message
from loguru import logger
import httpx

from app.config import settings

router = Router()

# Global variable to store model instance (will be set in main.py)
model_instance = None


def set_model_instance(model):
    """Set the global model instance"""
    global model_instance
    model_instance = model


async def predict_via_api(image_path: str) -> tuple[str, float]:
    """
    Make prediction using FastAPI service

    Args:
        image_path: Path to image file

    Returns:
        Tuple of (predicted_label, confidence)
    """
    try:
        async with httpx.AsyncClient(timeout=settings.api_timeout) as client:
            with open(image_path, 'rb') as f:
                files = {'file': f}
                response = await client.post(
                    f"{settings.api_url}/predict",
                    files=files
                )
                response.raise_for_status()
                data = response.json()
                return data['class'], data['probability']
    except Exception as e:
        logger.error(f"Error calling API service: {e}")
        raise


async def predict_via_model(image_path: str) -> tuple[str, float]:
    """
    Make prediction using local model

    Args:
        image_path: Path to image file

    Returns:
        Tuple of (predicted_label, confidence)
    """
    if model_instance is None:
        raise RuntimeError("Model instance not initialized")

    return model_instance.predict(image_path)


def format_breed_name(breed: str) -> str:
    """Format breed name for display"""
    # Replace underscores with spaces and capitalize words
    return breed.replace('_', ' ').title()


@router.message(F.photo)
async def handle_photo(message: Message):
    """Handle photo messages"""
    logger.info(f"Received photo from user {message.from_user.id}")

    # Send processing message
    processing_msg = await message.answer("üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é...")

    try:
        # Get the largest photo
        photo = message.photo[-1]
        file_id = photo.file_id

        # Download photo
        file = await message.bot.get_file(file_id)
        file_path = file.file_path

        # Create temp directory if not exists
        temp_dir = settings.temp_dir
        temp_dir.mkdir(parents=True, exist_ok=True)

        # Save photo locally
        local_file_path = temp_dir / f"{file_id}.jpg"
        await message.bot.download_file(file_path, local_file_path)

        logger.info(f"Photo saved to {local_file_path}")

        # Make prediction
        if settings.use_api_service:
            predicted_label, confidence = await predict_via_api(str(local_file_path))
        else:
            predicted_label, confidence = await predict_via_model(str(local_file_path))

        # Format breed name
        breed_display = format_breed_name(predicted_label)

        # Prepare response based on confidence
        if confidence >= settings.confidence_threshold:
            response_text = (
                f"‚úÖ <b>–†–µ–∑—É–ª—å—Ç–∞—Ç:</b>\n\n"
                f"üêæ –≠—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ <b>{breed_display}</b>\n"
                f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: <b>{confidence*100:.1f}%</b>\n\n"
                f"–ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–≤–µ—Ä–µ–Ω–∞ –≤ —Å–≤–æ—ë–º –æ—Ç–≤–µ—Ç–µ!"
            )
        else:
            response_text = (
                f"ü§î <b>–†–µ–∑—É–ª—å—Ç–∞—Ç:</b>\n\n"
                f"üêæ –í–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ <b>{breed_display}</b>\n"
                f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: <b>{confidence*100:.1f}%</b>\n\n"
                f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –æ—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–µ —Ñ–æ—Ç–æ —Å –ª—É—á—à–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º."
            )

        # Delete processing message
        await processing_msg.delete()

        # Send result
        await message.answer(response_text, parse_mode="HTML")

        # Clean up temporary file
        try:
            os.remove(local_file_path)
            logger.info(f"Cleaned up temporary file: {local_file_path}")
        except Exception as e:
            logger.warning(f"Failed to delete temporary file: {e}")

    except Exception as e:
        logger.error(f"Error processing photo: {e}")
        await processing_msg.delete()
        await message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏. "
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –¥—Ä—É–≥–æ–µ —Ñ–æ—Ç–æ."
        )


@router.message(F.document)
async def handle_document(message: Message):
    """Handle document messages (reject them)"""
    await message.answer(
        "‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ —Ñ–æ—Ç–æ, –∞ –Ω–µ –∫–∞–∫ —Ñ–∞–π–ª.\n"
        "–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∑–Ω–∞—á–æ–∫ —Å–∫—Ä–µ–ø–∫–∏ –∏ –≤—ã–±–µ—Ä–∏—Ç–µ '–§–æ—Ç–æ' –≤–º–µ—Å—Ç–æ '–§–∞–π–ª'."
    )


@router.message(F.text)
async def handle_text(message: Message):
    """Handle text messages that are not commands"""
    # Skip if message is a button text (already handled by start.py)
    if message.text in ["‚ÑπÔ∏è –ü–æ–º–æ—â—å", "üìä –û –ø—Ä–æ–µ–∫—Ç–µ"]:
        return

    await message.answer(
        "üì∏ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –ø–∏—Ç–æ–º—Ü–∞, "
        "–∏ —è –æ–ø—Ä–µ–¥–µ–ª—é –µ–≥–æ –ø–æ—Ä–æ–¥—É!\n\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /help –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
    )
